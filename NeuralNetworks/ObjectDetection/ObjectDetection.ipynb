{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment: Detect objects in images\n",
    "\n",
    "There’s an old saying in AI that computers are great at things that humans find hard (like doing complex math) and computers really struggle with things that humans find easy (like catching a ball or recognizing objects).\n",
    "Let’s take recognizing objects as an example. Check out the following collection of images:\n",
    "\n",
    "![Sample ImageNet images](./assets/images1.png)\n",
    "\n",
    "These 20 images depict a broccoli, a canoe, a coffee pot, a pizza, a teddy bear, and a toaster. How hard would it be to build an app that can recognize the object in every image?\n",
    "\n",
    "Really hard, actually.\n",
    "\n",
    "In fact, it’s so difficult that there’s an annual challenge called the **ImageNet Large Scale Visual Recognition Challenge**. The challenge requires apps to classify a collection of 1.2 million images into 1,000 unique categories.\n",
    "\n",
    "Here are the competition results up to 2016:\n",
    "\n",
    "![ImageNet results](./assets/imagenet-results.png)\n",
    "\n",
    "The red line depicts the 5% human error rate on the image classification challenge. Only in 2015 a team finally developed an app that could beat human performance levels.\n",
    "\n",
    "That was 4 years ago. Can we build a C# app today with ML.NET and NET Core that can do the same?\n",
    "\n",
    "You may think that the answer is yes, but that you'll have to build a complex convolutional neural network in ML.NET, train it on the 1.2 million images in the ImageNet set, and then use the trained network to predict the 20 images in our test set.\n",
    "\n",
    "But there’s no need to go through all that trouble. Fully-trained object-detection networks are readily available and ML.NET can easily host and run a neural network that has already been trained.\n",
    "\n",
    "So our best course of action is to grab a TensorFlow neural network that has been trained on the ImageNet data and just drop it into ML.NET for immediate use.\n",
    "\n",
    "You will use the **Google Inception** network in your app. What makes the Inception model unique is its use of stacked ‘Inception Modules’: special neural submodules that run convolutions with different kernel sizes in parallel, like this:\n",
    "\n",
    "![Inception modules](./assets/inception-modules.png)\n",
    "\n",
    "This is a single inception module shown in Netron, a popular neural network viewer (you can install Netron from here: https://github.com/lutzroeder/netron). The three convolution kernels (1x1, 3x3, and 5x5) are highlighted in red and run in parallel.\n",
    "\n",
    "This trick of running several different convolutions in parallel gives Inception excellent predictive ability on a wide range of images.\n",
    "\n",
    "You will also use a folder with the test images shown above and their corresponding labels. The file with the labels looks like this:\n",
    "\n",
    "![Training labels](./assets/labels.png)\n",
    "\n",
    "It’s a tab-separated file with only 2 columns of data:\n",
    "\n",
    "* The filename of the image to test\n",
    "* The type of object in the image\n",
    "\n",
    "## Get started\n",
    "\n",
    "Let’s get started. Here’s how to install the ML.NET packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Installing package SciSharp.TensorFlow.Redist....."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Installed package Microsoft.ML version 1.4.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Installed package Microsoft.ML.TensorFlow version 1.4.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Installed package Microsoft.ML.ImageAnalytics version 1.4.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#r nuget:SciSharp.TensorFlow.Redist\n",
    "#r nuget:Microsoft.ML\n",
    "#r nuget:Microsoft.ML.ImageAnalytics\n",
    "#r nuget:Microsoft.ML.TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **TensorFlow.Redist** package contains the redistributable files for the TensorFlow neural network library. The **ImageAnalytics** package contains libraries that help ML.NET deal with image data. And the **ML.Tensorflow** package adds support for running pretrained TensorFlow models directly in an ML.NET pipeline.\n",
    "\n",
    "Now you're ready to add some code. You will have to declare one class to hold an image record and one to hold your model’s predictions.\n",
    "\n",
    "Run the following code snippet to set up these classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Microsoft.ML;\n",
    "using Microsoft.ML.Data;\n",
    "using System.IO;\n",
    "\n",
    "public class ImageNetData\n",
    "{\n",
    "    [LoadColumn(0)] public string ImagePath;\n",
    "    [LoadColumn(1)] public string Label;\n",
    "\n",
    "    public static IEnumerable<ImageNetData> ReadFromCsv(string file)\n",
    "    {\n",
    "        return File.ReadAllLines(file)\n",
    "            .Select(x => x.Split('\\t'))\n",
    "            .Select(x => new ImageNetData \n",
    "            { \n",
    "                ImagePath = x[0], \n",
    "                Label = x[1] \n",
    "            });\n",
    "    }\n",
    "}\n",
    "\n",
    "public class ImageNetPrediction\n",
    "{\n",
    "    [ColumnName(\"softmax2\")]\n",
    "    public float[] PredictedLabels;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **ImageNetData** class holds one single image record. Note how each field is tagged with a **LoadColumn** attribute that tells the CSV data loading code which column to import data from.\n",
    "\n",
    "There’s also a **ReadFromCsv** method which manually reads a file and returns a sequence of **ImageNetData** objects. You will need this method later.\n",
    "\n",
    "There is also an **ImageNetPrediction** class which will hold a single image prediction.\n",
    "\n",
    "## Loading the data\n",
    "\n",
    "Now you're going to load the images in memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "// create a machine learning context\n",
    "var mlContext = new MLContext();\n",
    "\n",
    "// load the TSV file with image names and corresponding labels\n",
    "var data = mlContext.Data.LoadFromTextFile<ImageNetData>(\"images/tags.tsv\", hasHeader: true);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code uses the method **LoadFromTextFile** to load the TSV data directly into memory. The class field annotations tell the method how to store the loaded data in the **ImageNetData** class.\n",
    "\n",
    "Let's see if the data loaded correctly. We're going to deserialize the image data into an enumeration of **ImageNetData** instances and do a quick visual check of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><thead><tr><th><i>index</i></th><th>ImagePath</th><th>Label</th></tr></thead><tbody><tr><td>0</td><td>broccoli.png</td><td>broccoli</td></tr><tr><td>1</td><td>canoe2.jpg</td><td>canoe</td></tr><tr><td>2</td><td>canoe3.jpg</td><td>canoe</td></tr><tr><td>3</td><td>canoe4.jpg</td><td>canoe</td></tr><tr><td>4</td><td>coffeepot.jpg</td><td>coffeepot</td></tr><tr><td>5</td><td>coffeepot2.jpg</td><td>coffeepot</td></tr><tr><td>6</td><td>coffeepot3.jpg</td><td>coffeepot</td></tr><tr><td>7</td><td>coffeepot4.jpg</td><td>coffeepot</td></tr><tr><td>8</td><td>pizza.jpg</td><td>pizza</td></tr><tr><td>9</td><td>pizza2.jpg</td><td>pizza</td></tr></tbody></table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "// get an array of heartdata instances\n",
    "var preview = mlContext.Data.CreateEnumerable<ImageNetData>(data, reuseRowObject: false).ToArray();\n",
    "\n",
    "// display the result\n",
    "display(preview.Take(10));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks good. We're seeing the filenames of each image in the column **ImagePath** and their corresponding labels in the column **Label**. It seems our first 10 images contain one broccoli, three canoes, four coffee pots, and two pizzas.  \n",
    "\n",
    "## Training the model\n",
    "\n",
    "Now you're ready to start building the machine learning model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model....done\n"
     ]
    }
   ],
   "source": [
    "// set up a learning pipeline\n",
    "var pipeline = mlContext.Transforms\n",
    "\n",
    "    // step 1: load the images\n",
    "    .LoadImages(\n",
    "        outputColumnName: \"input\", \n",
    "        imageFolder: \"images\", \n",
    "        inputColumnName: nameof(ImageNetData.ImagePath))\n",
    "\n",
    "    // step 2: resize the images to 224x224\n",
    "    .Append(mlContext.Transforms.ResizeImages(\n",
    "        outputColumnName: \"input\", \n",
    "        imageWidth: 224, \n",
    "        imageHeight: 224, \n",
    "        inputColumnName: \"input\"))\n",
    "\n",
    "    // step 3: extract pixels in a format the TF model can understand\n",
    "    // these interleave and offset values are identical to the images the model was trained on\n",
    "    .Append(mlContext.Transforms.ExtractPixels(\n",
    "        outputColumnName: \"input\", \n",
    "        interleavePixelColors: true, \n",
    "        offsetImage: 117))\n",
    "\n",
    "    // step 4: load the TensorFlow model\n",
    "    .Append(mlContext.Model.LoadTensorFlowModel(\"models/tensorflow_inception_graph.pb\")\n",
    "\n",
    "    // step 5: score the images using the TF model\n",
    "    .ScoreTensorFlowModel(\n",
    "        outputColumnNames: new[] { \"softmax2\" },\n",
    "        inputColumnNames: new[] { \"input\" }, \n",
    "        addBatchDimensionInput:true));\n",
    "            \n",
    "// train the model on the data file\n",
    "Console.Write(\"Training model....\");\n",
    "var model = pipeline.Fit(data);\n",
    "Console.WriteLine(\"done\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine learning models in ML.NET are built with pipelines, which are sequences of data-loading, transformation, and learning components.\n",
    "\n",
    "This pipeline has the following components:\n",
    "\n",
    "* **LoadImages** which loads images from disk. The component needs the name of the input column holding the file names, the folder in which to look for images, and the name of the output column to load images into.\n",
    "* **ResizeImages** which resizes images. This is a required step because the inception model has been trained on 224x224 pixel images. So we need to present our images using the same size for the model to work (*)\n",
    "* **ExtractPixels** which flattens the image data into a 1-dimensional array of floats. Note that we interleave color channels and use an offset of 117, because that’s what the Inception model has been trained on (*)\n",
    "* **LoadTensorFlowModel** which will load a TensorFlow model from disk.\n",
    "* **ScoreTensorFlowModel** which will feed the image data into the TensorFlow model and collect the scores from the dense classifier at the output side.\n",
    "\n",
    "(*) As a rule when working with pre-trained neural networks, we need to preprocess our images in the exact same way as the data the network has been trained on. In case of ImageNet this means resizing all images to 224x224, interleaving color channels, and using a pixel offset value of 117.\n",
    "\n",
    "The **ScoreTensorFlowModel** component requires the name of the input node that will receive the image data and the name of the output node that holds the softmax predictions.\n",
    "\n",
    "We can easily find these nodes by viewing the Inception model in Netron. This is the neural network input, with an id of **input**:\n",
    "\n",
    "![Inception input node](./assets/inception-input.png)\n",
    "\n",
    "And here is the softmax classifier at the output, with an id of **softmax2**:\n",
    "\n",
    "![Inception output node](./assets/inception-output.png)\n",
    "\n",
    "So the two node names we have to provide to **ScoreTensorFlowModel** are **input** and **softmax2**.\n",
    "\n",
    "With the pipeline fully assembled, we can train the model with a call to **Fit**.\n",
    "\n",
    "Note that training doesn’t actually do anything here. The TensorFlow model is already fully trained and all model parameters are frozen. So in this case, the Fit method just assembles the pipeline and returns a model instance.\n",
    "\n",
    "## Making predictions\n",
    "\n",
    "To wrap up, We're going to create a prediction engine to analyze each image in the set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "// create a prediction engine\n",
    "var engine = mlContext.Model.CreatePredictionEngine<ImageNetData, ImageNetPrediction>(model);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the **CreatePredictionEngine** method to set up a prediction engine. The two type arguments are the input data class and the class to hold the prediction.\n",
    "\n",
    "Next, we're going to load the complete list of ImageNet labels from a text file stored in the Inception model folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><thead><tr><th><i>index</i></th><th>value</th></tr></thead><tbody><tr><td>0</td><td>dummy</td></tr><tr><td>1</td><td>kit fox</td></tr><tr><td>2</td><td>English setter</td></tr><tr><td>3</td><td>Siberian husky</td></tr><tr><td>4</td><td>Australian terrier</td></tr><tr><td>5</td><td>English springer</td></tr><tr><td>6</td><td>grey whale</td></tr><tr><td>7</td><td>lesser panda</td></tr><tr><td>8</td><td>Egyptian cat</td></tr><tr><td>9</td><td>ibex</td></tr></tbody></table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "// load all imagenet labels\n",
    "var labels = File.ReadAllLines(\"models/imagenet_comp_graph_label_strings.txt\");\n",
    "display(labels.Take(10));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It’s just a list of all 1,000 unique ImageNet category labels. We need this file to match each model predictions to its corresponding label so we know what the model 'sees' in the image.\n",
    "\n",
    "We're also going to load the 20 test images with their labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><thead><tr><th><i>index</i></th><th>ImagePath</th><th>Label</th></tr></thead><tbody><tr><td>0</td><td>broccoli.jpg</td><td>broccoli</td></tr><tr><td>1</td><td>broccoli.png</td><td>broccoli</td></tr><tr><td>2</td><td>canoe2.jpg</td><td>canoe</td></tr><tr><td>3</td><td>canoe3.jpg</td><td>canoe</td></tr><tr><td>4</td><td>canoe4.jpg</td><td>canoe</td></tr><tr><td>5</td><td>coffeepot.jpg</td><td>coffeepot</td></tr><tr><td>6</td><td>coffeepot2.jpg</td><td>coffeepot</td></tr><tr><td>7</td><td>coffeepot3.jpg</td><td>coffeepot</td></tr><tr><td>8</td><td>coffeepot4.jpg</td><td>coffeepot</td></tr><tr><td>9</td><td>pizza.jpg</td><td>pizza</td></tr></tbody></table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "// predict what is in each image\n",
    "var images = ImageNetData.ReadFromCsv(\"images/tags.tsv\");\n",
    "display(images.Take(10));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've seen this before: this is again the list of images to test, with their corresponding labels.\n",
    "\n",
    "Our final step is to use the prediction engine to make a prediction for each image in the set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting image contents:\n",
      "  [broccoli.jpg]: "
     ]
    },
    {
     "ename": "Unhandled exception",
     "evalue": "System.TypeInitializationException: The type initializer for 'Gdip' threw an exception.\n ---> System.TypeInitializationException: The type initializer for 'System.Drawing.LibraryResolver' threw an exception.\n ---> System.InvalidOperationException: A resolver is already set for the assembly.\n   at System.Runtime.InteropServices.NativeLibrary.SetDllImportResolver(Assembly assembly, DllImportResolver resolver)\n   at System.Drawing.LibraryResolver..cctor()\n   --- End of inner exception stack trace ---\n   at System.Drawing.SafeNativeMethods.Gdip..cctor()\n   --- End of inner exception stack trace ---\n   at System.Drawing.SafeNativeMethods.Gdip.GdipCreateBitmapFromFile(String filename, IntPtr& bitmap)\n   at System.Drawing.Bitmap..ctor(String filename, Boolean useIcm)\n   at System.Drawing.Bitmap..ctor(String filename)\n   at Microsoft.ML.Data.ImageLoadingTransformer.Mapper.<>c__DisplayClass4_0.<MakeGetterImageDataViewType>b__0(Bitmap& dst)\n   at Microsoft.ML.Transforms.Image.ImageResizingTransformer.Mapper.<>c__DisplayClass3_0.<MakeGetter>b__1(Bitmap& dst)\n   at Microsoft.ML.Transforms.Image.ImagePixelExtractingTransformer.Mapper.<>c__DisplayClass5_0`1.<GetGetterCore>b__1(VBuffer`1& dst)\n   at Microsoft.ML.Transforms.TensorFlowTransformer.TensorValueGetterVec`1.GetTensor()\n   at Microsoft.ML.Transforms.TensorFlowTransformer.Mapper.UpdateCacheIfNeeded(Int64 position, ITensorValueGetter[] srcTensorGetters, String[] activeOutputColNames, OutputCache outputCache)\n   at Microsoft.ML.Transforms.TensorFlowTransformer.Mapper.<>c__DisplayClass9_0`1.<MakeGetter>b__4(VBuffer`1& dst)\n   at Microsoft.ML.Data.TypedCursorable`1.TypedRowBase.<>c__DisplayClass8_0`1.<CreateDirectVBufferSetter>b__0(TRow row)\n   at Microsoft.ML.Data.TypedCursorable`1.TypedRowBase.FillValues(TRow row)\n   at Microsoft.ML.Data.TypedCursorable`1.RowImplementation.FillValues(TRow row)\n   at Microsoft.ML.PredictionEngineBase`2.FillValues(TDst prediction)\n   at Microsoft.ML.PredictionEngine`2.Predict(TSrc example, TDst& prediction)\n   at Microsoft.ML.PredictionEngineBase`2.Predict(TSrc example)\n   at Submission#7.<<Initialize>>d__0.MoveNext()\n--- End of stack trace from previous location where exception was thrown ---\n   at Microsoft.CodeAnalysis.Scripting.ScriptExecutionState.RunSubmissionsAsync[TResult](ImmutableArray`1 precedingExecutors, Func`2 currentExecutor, StrongBox`1 exceptionHolderOpt, Func`2 catchExceptionOpt, CancellationToken cancellationToken)",
     "output_type": "error",
     "traceback": [
      "System.TypeInitializationException: The type initializer for 'Gdip' threw an exception.\n ---> System.TypeInitializationException: The type initializer for 'System.Drawing.LibraryResolver' threw an exception.\n ---> System.InvalidOperationException: A resolver is already set for the assembly.\n   at System.Runtime.InteropServices.NativeLibrary.SetDllImportResolver(Assembly assembly, DllImportResolver resolver)\n   at System.Drawing.LibraryResolver..cctor()\n   --- End of inner exception stack trace ---\n   at System.Drawing.SafeNativeMethods.Gdip..cctor()\n   --- End of inner exception stack trace ---\n   at System.Drawing.SafeNativeMethods.Gdip.GdipCreateBitmapFromFile(String filename, IntPtr& bitmap)\n   at System.Drawing.Bitmap..ctor(String filename, Boolean useIcm)\n   at System.Drawing.Bitmap..ctor(String filename)\n   at Microsoft.ML.Data.ImageLoadingTransformer.Mapper.<>c__DisplayClass4_0.<MakeGetterImageDataViewType>b__0(Bitmap& dst)\n   at Microsoft.ML.Transforms.Image.ImageResizingTransformer.Mapper.<>c__DisplayClass3_0.<MakeGetter>b__1(Bitmap& dst)\n   at Microsoft.ML.Transforms.Image.ImagePixelExtractingTransformer.Mapper.<>c__DisplayClass5_0`1.<GetGetterCore>b__1(VBuffer`1& dst)\n   at Microsoft.ML.Transforms.TensorFlowTransformer.TensorValueGetterVec`1.GetTensor()\n   at Microsoft.ML.Transforms.TensorFlowTransformer.Mapper.UpdateCacheIfNeeded(Int64 position, ITensorValueGetter[] srcTensorGetters, String[] activeOutputColNames, OutputCache outputCache)\n   at Microsoft.ML.Transforms.TensorFlowTransformer.Mapper.<>c__DisplayClass9_0`1.<MakeGetter>b__4(VBuffer`1& dst)\n   at Microsoft.ML.Data.TypedCursorable`1.TypedRowBase.<>c__DisplayClass8_0`1.<CreateDirectVBufferSetter>b__0(TRow row)\n   at Microsoft.ML.Data.TypedCursorable`1.TypedRowBase.FillValues(TRow row)\n   at Microsoft.ML.Data.TypedCursorable`1.RowImplementation.FillValues(TRow row)\n   at Microsoft.ML.PredictionEngineBase`2.FillValues(TDst prediction)\n   at Microsoft.ML.PredictionEngine`2.Predict(TSrc example, TDst& prediction)\n   at Microsoft.ML.PredictionEngineBase`2.Predict(TSrc example)\n   at Submission#7.<<Initialize>>d__0.MoveNext()\n--- End of stack trace from previous location where exception was thrown ---\n   at Microsoft.CodeAnalysis.Scripting.ScriptExecutionState.RunSubmissionsAsync[TResult](ImmutableArray`1 precedingExecutors, Func`2 currentExecutor, StrongBox`1 exceptionHolderOpt, Func`2 catchExceptionOpt, CancellationToken cancellationToken)",
      "   at System.Drawing.SafeNativeMethods.Gdip.GdipCreateBitmapFromFile(String filename, IntPtr& bitmap)",
      "   at System.Drawing.Bitmap..ctor(String filename, Boolean useIcm)",
      "   at System.Drawing.Bitmap..ctor(String filename)",
      "   at Microsoft.ML.Data.ImageLoadingTransformer.Mapper.<>c__DisplayClass4_0.<MakeGetterImageDataViewType>b__0(Bitmap& dst)",
      "   at Microsoft.ML.Transforms.Image.ImageResizingTransformer.Mapper.<>c__DisplayClass3_0.<MakeGetter>b__1(Bitmap& dst)",
      "   at Microsoft.ML.Transforms.Image.ImagePixelExtractingTransformer.Mapper.<>c__DisplayClass5_0`1.<GetGetterCore>b__1(VBuffer`1& dst)",
      "   at Microsoft.ML.Transforms.TensorFlowTransformer.TensorValueGetterVec`1.GetTensor()",
      "   at Microsoft.ML.Transforms.TensorFlowTransformer.Mapper.UpdateCacheIfNeeded(Int64 position, ITensorValueGetter[] srcTensorGetters, String[] activeOutputColNames, OutputCache outputCache)",
      "   at Microsoft.ML.Transforms.TensorFlowTransformer.Mapper.<>c__DisplayClass9_0`1.<MakeGetter>b__4(VBuffer`1& dst)",
      "   at Microsoft.ML.Data.TypedCursorable`1.TypedRowBase.<>c__DisplayClass8_0`1.<CreateDirectVBufferSetter>b__0(TRow row)",
      "   at Microsoft.ML.Data.TypedCursorable`1.TypedRowBase.FillValues(TRow row)",
      "   at Microsoft.ML.Data.TypedCursorable`1.RowImplementation.FillValues(TRow row)",
      "   at Microsoft.ML.PredictionEngineBase`2.FillValues(TDst prediction)",
      "   at Microsoft.ML.PredictionEngine`2.Predict(TSrc example, TDst& prediction)",
      "   at Microsoft.ML.PredictionEngineBase`2.Predict(TSrc example)",
      "   at Submission#7.<<Initialize>>d__0.MoveNext()",
      "--- End of stack trace from previous location where exception was thrown ---",
      "   at Microsoft.CodeAnalysis.Scripting.ScriptExecutionState.RunSubmissionsAsync[TResult](ImmutableArray`1 precedingExecutors, Func`2 currentExecutor, StrongBox`1 exceptionHolderOpt, Func`2 catchExceptionOpt, CancellationToken cancellationToken)"
     ]
    }
   ],
   "source": [
    "Console.WriteLine(\"Predicting image contents:\");\n",
    "foreach (var image in images)\n",
    "{\n",
    "    Console.Write($\"  [{image.ImagePath}]: \");\n",
    "    var prediction = engine.Predict(image).PredictedLabels;\n",
    "\n",
    "    // find the best prediction\n",
    "    var i = 0;\n",
    "    var best = (from p in prediction \n",
    "                select new { Index = i++, Prediction = p }).OrderByDescending(p => p.Prediction).First();\n",
    "    var predictedLabel = labels[best.Index];\n",
    "\n",
    "    // show the corresponding label\n",
    "    Console.WriteLine($\"{predictedLabel} {(predictedLabel != image.Label ? \"***WRONG***\" : \"\")}\");\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code loops through each image and calls **Predict** to make a prediction for each one. That gives us an array of 1,000 floats of probabilities corresponding to each category.\n",
    "\n",
    "In other words, prediction[1] is the probability that the image contains a Kit Fox, prediction[2] is the probability that the image contains an English Setter, and so on.\n",
    "\n",
    "We are only interested in the best prediction, so the code uses a LINQ query to find the highest value and the corresponding category label.\n",
    "\n",
    "The app is quite fast and can identify an image in a fraction of a second. It does a really good job on the test set and correctly identifies 19 out of 20 images. That’s an accuracy of 95%.\n",
    "\n",
    "The app only made one single mistake and predicted that coffeepot4.jpg is actually a pitcher of water:\n",
    "\n",
    "![Prediction results](./assets/results.png)\n",
    "\n",
    "## Further improvements\n",
    "\n",
    "How do you think we can improve the accuracy of the model even further?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".NET (C#)",
   "language": "C#",
   "name": ".net-csharp"
  },
  "language_info": {
   "file_extension": ".cs",
   "mimetype": "text/x-csharp",
   "name": "C#",
   "pygments_lexer": "csharp",
   "version": "8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
